<!doctype html><html><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="A repository for my thoughts"><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=icon type=image/x-icon href=/favicon.ico><link rel=stylesheet href=/css/style.min.css><meta name=title property=”og:title” content="Making a Tsunami | Haile (ሐይሌ)"><meta name=twitter:card content="summary"><meta name=twitter:title content="Making a Tsunami | Haile (ሐይሌ)"><meta name=description content><meta property="og:description" content><meta name=twitter:description content><meta name=twitter:creator content="@hailelagi"><title>Making a Tsunami</title></head><body><header id=banner><h2><a href=https://www.hailelagi.com/>Haile (ሐይሌ)</a></h2><nav><ul><li><a href=/bookshelf title=bookshelf>bookshelf</a></li><li><a href=https://www.github.com/hailelagi title=github>github</a></li><li><a href=/notes title=writing>writing</a></li></ul></nav></header><main id=content><article><header id=post-header><h1>Making a Tsunami</h1><time>April 4, 2024</time><meta name=twitter:card content="summary">
<meta property="og:url" content="https://www.hailelagi.com/"><meta property="og:image" content="/favicon-32x32.png"><meta itemprop=image content="/favicon-32x32.png"><meta name=twitter:image content="/favicon-32x32.png"><meta name=twitter:image:src content="/favicon-32x32.png"></header><p>⚠️⚠️⚠️⚠️
This a WIP draft
⚠️⚠️⚠️⚠️</p><p>Building a <a href=https://en.wikipedia.org/wiki/Embedded_database>runtime-embeddable</a>, in-memory, <a href=https://en.wikipedia.org/wiki/In-memory_database>key value store</a> for messaging, streaming queries and soft-realtime applications. Main memory databases form
the core of many platforms and are used for creating leaderboards, caches, pubsub and messaging apps. Popular examples are Redis, Memcached and BerkeleyDB.</p><h2 id=introduction>Introduction</h2><p>Tsunami intends to be a performant and ergonomic <em>alternative</em> key/value store with an intuitive dataframe api capable of querying larger than memory datasets. It can be embeddable with any BEAM compatible language: erlang, elixir, gleam etc and offers a backwards-compatible but different take on the default erlang term storage (<code>:ets</code>), if familiar with the elixir ecosystem, it sits somewhere in the middle of explorer and ets itself.</p><p>But before that context, here&rsquo;s Joe Armstrong explaining why writing correct, fast, well-tested, concurrent/ parallel and distributed programs on modern CPUs is complex and difficult and why erlang/elixir is appealing, it comes with a concurrent/parallel garbage collector (no global GC pauses, <strong>low-latency by default</strong>), a <strong>shared nothing architecture</strong> runtime that&rsquo;s <strong>multi-core by default</strong>, scales I/O bound soft realtime applications incredibly well with a simple model of concurrency that <strong>eliminates data races</strong> and primitives that encourage thinking about fault tolerance &ndash; did I mention functional programming?</p><div style=position:relative;padding-bottom:56.25%;height:0;overflow:hidden><iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen loading=eager referrerpolicy=strict-origin-when-cross-origin src="https://www.youtube.com/embed/bo5WL5IQAd0?autoplay=0&controls=1&end=0&loop=0&mute=0&start=0" style=position:absolute;top:0;left:0;width:100%;height:100%;border:0 title="YouTube video"></iframe></div><p>This covers some wide ranging and complex important topics, let&rsquo;s take a peek under the covers of what we say &ldquo;yes&rdquo; to when we want <em>shared
memory concurrency</em> &ndash; spoiler it&rsquo;s hard, Joe&rsquo;s advice is let a small group muck about with these gnarly problems and produce nice clean abstractions
like the <a href=https://www.erlang.org/doc/reference_manual/processes>process model</a>. However rust sells itself on the basis of memory safety and <a href=https://blog.rust-lang.org/2015/04/10/Fearless-Concurrency.html>fearless concurrency</a>, is there a way to combine the two?</p><p><img src=/crit.png alt=Danger></p><h2 id=shaping-constraints>Shaping constraints</h2><p>It&rsquo;s a worrying premise to write programs in an environment that doesn&rsquo;t have any kind of shared state: it seems wasteful and slow to just go around copying all your data structures †<sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>. In the erlang/elixir ecosystem this is solved by leveraging erlang term storage and it&rsquo;s a key component of the distributed persistent database mnesia all built aware of the language runtime(BEAM).</p><blockquote><p>It would be very difficult, if not impossible to implement ETS purely in Erlang with similar performance. Due to its reliance on mutable data, the functionality of ETS tables is very expensive to model in a functional programming language like Erlang. <sup id=fnref:2><a href=#fn:2 class=footnote-ref role=doc-noteref>2</a></sup></p></blockquote><p>Before we get into the bells and whistles of it all, what is <code>ets</code> at its core? Conceputally a key-value store seems simple.
What you want to model is an abstract interface that can store <em>schemaless</em> data(strings, integers, arrays &ndash; anything) and retrieve it fast, essentially a map/dictionary/associative array abstract data type. Let&rsquo;s see an interface example <code>Table</code> in go:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span> <span class=nx>Table</span><span class=p>[</span><span class=nx>Key</span> <span class=nx>comparable</span><span class=p>,</span> <span class=nx>Value</span> <span class=nx>any</span><span class=p>]</span> <span class=kd>interface</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nf>Get</span><span class=p>(</span><span class=nx>Key</span><span class=p>)</span> <span class=p>(</span><span class=nx>Value</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=nf>Put</span><span class=p>(</span><span class=nx>Key</span><span class=p>,</span> <span class=nx>Value</span><span class=p>)</span> <span class=kt>error</span>
</span></span><span class=line><span class=cl>  <span class=nf>Delete</span><span class=p>(</span><span class=nx>Key</span><span class=p>)</span> <span class=kt>error</span>
</span></span><span class=line><span class=cl>  <span class=nf>In</span><span class=p>(</span><span class=nx>Key</span><span class=p>)</span> <span class=kt>bool</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>We also want flexible <strong>data modelling</strong> options to pass for this <code>Table</code>, we&rsquo;re looking to define the instance options <code>bag</code>, <code>duplicate_bag</code>, <code>set</code> and <code>ordered_set</code>. If familiar with <code>table relations</code> aka relational algebra, think of the key-value mapping if you must as:</p><ol><li>one to one(1-1): is an unordered <code>set</code> of elements.</li><li>one to one(but with order) = is an <code>ordered_set</code> of unique elements.</li><li>one to many(1-N) = is a <code>bag</code> of elements of unique keys to many values.</li><li>many to many(N-N) = is a <code>duplicate_bag</code> of elements with keys and values that multi-map between them.</li></ol><p>These give use the raw materials(set theory) to model all sorts of interesting properties like <em>referential integrity</em> - a relationship between two or more tables or even express <em>true relational algebra</em> by implementing a <em>join</em> but we&rsquo;ll get to those gnarly problems <em>later</em>. For now, you might be thinking why not implement this by just throwing a hashmap underneath and that works for types <code>set</code>, <code>bag</code> and <code>duplicate_bag</code>. Infact hashmaps are ubiquitious <sup id=fnref:3><a href=#fn:3 class=footnote-ref role=doc-noteref>3</a></sup> <sup id=fnref:4><a href=#fn:4 class=footnote-ref role=doc-noteref>4</a></sup> <sup id=fnref:5><a href=#fn:5 class=footnote-ref role=doc-noteref>5</a></sup> and contain many excellent algorithmic properties: among them O(1) access, this is great, especially when the data set fits in working memory. However most implementations in standard libraries are not thread safe. CPU cores need to synchronize data access to avoid corrupting data or reading inconsistent or stale data. In rust - sharing an <code>std::collections::hash_map::HashMap</code> requires wrapping it in two things:</p><ol><li>the atomic reference count smart pointer <code>Arc&lt;T></code></li><li>a mutex or some other synchronization mechanism on the critical section because the type does not impl <code>Send</code> & <code>Sync</code></li></ol><p>If your program and data only has to exist within a single thread of execution that&rsquo;s great, but <em>web servers</em> tend to need to handle <em>concurrent</em> data access. Practical examples of this are caches, rate limiting middleware, session storage, distributed config, simple message queues etc</p><p>Let&rsquo;s do the simple thing first, let&rsquo;s guard/wrap our shiny key/value store in a mutex from go&rsquo;s std lib&rsquo;s <code>sync</code> package:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span> <span class=nx>Map</span><span class=p>[</span><span class=nx>K</span> <span class=kt>string</span><span class=p>,</span> <span class=nx>V</span> <span class=nx>any</span><span class=p>]</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=nx>sync</span><span class=p>.</span><span class=nx>Mutex</span>
</span></span><span class=line><span class=cl> <span class=nx>Data</span> <span class=kd>map</span><span class=p>[</span><span class=nx>K</span><span class=p>]</span><span class=nx>V</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>To <code>Read</code> and <code>Write</code> we must acquire <code>*Map.Lock()</code> and release <code>*Map.Unlock()</code>. This works, up to a point &ndash;
but we can do better! We&rsquo;re trying to build a <em>general purpose</em> data store for
key-value data. Global Mutexes are a good solution but you tend to encounter inefficiencies like <em>lock contention</em> on higher values of R/W data access, especially when your hardware can parallelize computation when the memory region&rsquo;s slots are partioned due to hashing across independent memory regions and threads.</p><p>The &ldquo;clever&rdquo; way of getting around this is by using more concurrency. A technique called fine-grained locking, the general idea is instead of a global mutex we serialise access to specific partitions or multiple levels, the idea being we want to seperate read access from write access<sup id=fnref:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span> <span class=nx>Map</span><span class=p>[</span><span class=nx>K</span> <span class=kt>string</span><span class=p>,</span> <span class=nx>V</span> <span class=nx>any</span><span class=p>]</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl> <span class=nx>Data</span>  <span class=kd>map</span><span class=p>[</span><span class=nx>K</span><span class=p>]</span><span class=nx>V</span>
</span></span><span class=line><span class=cl> <span class=nx>locks</span> <span class=p>[]</span><span class=o>*</span><span class=nx>sync</span><span class=p>.</span><span class=nx>Mutex</span>
</span></span><span class=line><span class=cl> <span class=nx>global</span> <span class=nx>sync</span><span class=p>.</span><span class=nx>Mutex</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>This adds some complexity but can be more write performant but suffer slightly slower reads - perhaps a Read-Writer Lock can save us? This bottleneck of locks and linearization is the reason databases have Multi Version Concurrency Control(MVCC) semantics for pushing reads and writes further using transactions and isolation levels. We&rsquo;ll come back to exploring these fun problems and the tradeoffs and ask the question are locks truely necessary?</p><p>Next, we&rsquo;d like to be able to store both ordered and unordered key value data, hash maps store unordered data so this calls for some sort of additional data structure with fast ordered <code>Table</code> operations for our <code>ordered_set</code>. We must define a new interface:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span> <span class=nx>OrderedTable</span><span class=p>[</span><span class=nx>Key</span> <span class=nx>cmp</span><span class=p>.</span><span class=nx>Ordered</span><span class=p>,</span> <span class=nx>Value</span> <span class=nx>any</span><span class=p>]</span> <span class=kd>interface</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nf>Get</span><span class=p>(</span><span class=nx>Key</span><span class=p>)</span> <span class=p>(</span><span class=nx>Value</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span>
</span></span><span class=line><span class=cl>  <span class=nf>Put</span><span class=p>(</span><span class=nx>Key</span><span class=p>,</span> <span class=nx>Value</span><span class=p>)</span> <span class=kt>error</span>
</span></span><span class=line><span class=cl>  <span class=nf>Delete</span><span class=p>(</span><span class=nx>Key</span><span class=p>)</span> <span class=kt>error</span>
</span></span><span class=line><span class=cl>  <span class=nf>In</span><span class=p>(</span><span class=nx>Key</span><span class=p>)</span> <span class=kt>bool</span>
</span></span><span class=line><span class=cl>  <span class=nf>Range</span><span class=p>(</span><span class=nx>Key</span><span class=p>,</span> <span class=nx>Key</span><span class=p>)</span> <span class=p>([]</span><span class=nx>Value</span><span class=p>,</span> <span class=kt>error</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>For the data structure, let&rsquo;s start with the conceptually simplest/fastest* <a href=https://github.com/hailelagi/porcupine/blob/main/porcupine/bst.go>a Binary Search Tree</a> protected by a global <code>RWMutex</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>type</span> <span class=nx>BST</span><span class=p>[</span><span class=nx>Key</span> <span class=nx>constraints</span><span class=p>.</span><span class=nx>Ordered</span><span class=p>,</span> <span class=nx>Value</span> <span class=nx>any</span><span class=p>]</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>root</span> <span class=o>*</span><span class=nx>BSTNode</span><span class=p>[</span><span class=nx>Key</span><span class=p>,</span> <span class=nx>Value</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=nx>sync</span><span class=p>.</span><span class=nx>RWMutex</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kd>type</span> <span class=nx>BSTNode</span><span class=p>[</span><span class=nx>Key</span> <span class=nx>constraints</span><span class=p>.</span><span class=nx>Ordered</span><span class=p>,</span> <span class=nx>Value</span> <span class=nx>any</span><span class=p>]</span> <span class=kd>struct</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=nx>key</span>   <span class=nx>Key</span>
</span></span><span class=line><span class=cl>	<span class=nx>value</span> <span class=nx>Value</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>	<span class=nx>left</span>  <span class=o>*</span><span class=nx>BSTNode</span><span class=p>[</span><span class=nx>Key</span><span class=p>,</span> <span class=nx>Value</span><span class=p>]</span>
</span></span><span class=line><span class=cl>	<span class=nx>right</span> <span class=o>*</span><span class=nx>BSTNode</span><span class=p>[</span><span class=nx>Key</span><span class=p>,</span> <span class=nx>Value</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p>Search trees are the &ldquo;go to&rdquo; structure for keeping performant ordered data with balanced read/write performance, by ensuring we keep the &ldquo;search property&rdquo; we can perform on average operations in <code>O(logN)</code> &ndash; if the tree is balanced. Sadly in reality they&rsquo;re bounded by the worst time-complexity of <code>O(h)</code> where h is the height of the tree. What that means is if we get unlucky
with the data - searches can devolve into searching a linked-list. That wouldn&rsquo;t do. Here there are many flavors thankfully.</p><p>Fan favorites include the classics; an AVL Tree, B-Tree or perhaps an LSM Tree, which all come with spices and even more variety.</p><p>In practice we are concerned about much more than order of magnitude choices, we are also interested in how these structures
interact with memory layout, can the data fit in main memory (internal) or is it on disk(external)? is it cache friendly? are the node values blocks of virtual memory(pages) fetched from disk? or random access? sorting files in a directory is a simple excercise that illustrates this problem. What kind of concurrent patterns are enabled? how do they map to our eventual high level API? These questions lead to very different choices in algorithm design and optimisations.</p><p>What exists in the current erlang runtime system? The data structure chosen previously of which we&rsquo;ll be benchmarking against is something called a <a href=https://www.erlang.org/blog/the-new-scalable-ets-ordered_set/>Contention Adapting Tree</a> <sup id=fnref1:6><a href=#fn:6 class=footnote-ref role=doc-noteref>6</a></sup>. Briefly what&rsquo;s interesting about CA Tree is it dynamically at runtime changes the behaviour and number of locks it holds across the tables it protects depending on nature of contention protecting underneath a sequential ordered data structure such as a treap or AVL Tree.</p><p>First an experiment with an AVL with weakened properties:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>pub</span><span class=w> </span><span class=k>struct</span> <span class=nc>WAVLTree</span><span class=o>&lt;</span><span class=n>K</span><span class=p>,</span><span class=w> </span><span class=n>V</span><span class=o>&gt;</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>root</span>: <span class=nb>Option</span><span class=o>&lt;</span><span class=nb>Box</span><span class=o>&lt;</span><span class=n>Node</span><span class=o>&lt;</span><span class=n>K</span><span class=p>,</span><span class=w> </span><span class=n>V</span><span class=o>&gt;&gt;&gt;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>struct</span> <span class=nc>Node</span><span class=o>&lt;</span><span class=n>K</span><span class=p>,</span><span class=w> </span><span class=n>V</span><span class=o>&gt;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>where</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>K</span>: <span class=nb>Send</span> <span class=o>+</span><span class=w> </span><span class=nb>Sync</span><span class=w> </span><span class=o>+</span><span class=w> </span><span class=n>cmp</span>::<span class=nb>Ord</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>V</span>: <span class=nb>Send</span> <span class=o>+</span><span class=w> </span><span class=nb>Sync</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>key</span>: <span class=nc>K</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>value</span>: <span class=nc>V</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>height</span>: <span class=kt>i32</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>left</span>: <span class=nb>Option</span><span class=o>&lt;</span><span class=nb>Box</span><span class=o>&lt;</span><span class=n>Node</span><span class=o>&lt;</span><span class=n>K</span><span class=p>,</span><span class=w> </span><span class=n>V</span><span class=o>&gt;&gt;&gt;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>right</span>: <span class=nb>Option</span><span class=o>&lt;</span><span class=nb>Box</span><span class=o>&lt;</span><span class=n>Node</span><span class=o>&lt;</span><span class=n>K</span><span class=p>,</span><span class=w> </span><span class=n>V</span><span class=o>&gt;&gt;&gt;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>Here we must <a href=https://eli.thegreenplace.net/2021/rust-data-structures-with-circular-references/>muck about with rust&rsquo;s ownership rules</a>. That&rsquo;s orthangonal to the goal though, what interesting properties have we gained and lost?</p><p>TODO(WIP) here: <a href=https://github.com/hailelagi/lettuce>https://github.com/hailelagi/lettuce</a></p><h2 id=concurrency-correctness--going-web-scale>Concurrency, Correctness & Going web scale</h2><p>These days are you a serious software craftsman <a href="https://www.youtube.com/watch?v=b2F-DItXtZs">if you&rsquo;re not at web scale?</a>.</p><p>In our undying, unending pursuit to scale systems further and further we spin webs of complexity. <a href="https://www.youtube.com/watch?v=RlwlV4hcBac">Why? No one knows what it means but it&rsquo;s provocative.</a></p><p>Let&rsquo;s put on our scaling cap. Previously we mentioned fine-grained locking as a technique that could lead to better write performance but at the cost of complexity and read performance &ndash; a related application of this technique is called &ldquo;sharding&rdquo;.</p><p>Sharding is a wonderful idea, if one hashmap won&rsquo;t work, let&rsquo;s scale <em>horizontally</em>, have you tried two? or perhaps sixteen or thirty two?
Java&rsquo;s <code>ConcurrentHashMap</code> and rust&rsquo;s <code>DashMap</code> are defacto examples of this. However we need to ask isn&rsquo;t this getting complex? can we still understand the system? most importantly can we guarantee <em>correctness?</em></p><p>As it turns out most databases need to ensure certain guarantees with respect to performance, concurrency and correctness and here we discuss the elusive idea of a &ldquo;transaction&rdquo;. You&rsquo;ve probably heard the acronymn ACID - Atomicity, Consistency, Isolation and Durability. What does that mean for ets? Lucky for us, we can cast away the durability requirement as our data set must fit in working memory(for now). That leaves us with:</p><ul><li>Atomicity</li><li>Consistency</li><li>Isolation</li></ul><h3 id=atomicity>Atomicity</h3><p>At the level of hardware what is atomicity? It&rsquo;s a special instruction set.
An example of an interface to this is go&rsquo;s <a href=https://pkg.go.dev/sync/atomic>sync/atomic</a>.
This instruction gives a certain <em>guarantee</em>,that you can perform an operation without <em>side effects</em>. You bake a pie or you don&rsquo;t &ndash; however we&rsquo;re getting ahead of ourselves as this part has to do with <em>visibility</em>.</p><p>Now here&rsquo;s where we have to be careful. ETS operations are <strong>atomic in a single operation per object/table</strong><sup id=fnref:7><a href=#fn:7 class=footnote-ref role=doc-noteref>7</a></sup>.</p><p>Every operation such as a read, write or multi_insert on a table are atomic as long as it&rsquo;s within a single function call/table access but <em>not across multiple</em>. In optimistic concurrency control a typical mechanism exposed by
row oriented OLTP databases like postgres, you have <code>BEGIN</code>, <code>COMMIT</code> & <code>ROLLBACK</code> semantics where you can <strong>group multiple write operations</strong> and pretend they&rsquo;re a single atomic operation. Mnesia builds upon
ets and supports <a href=https://www.erlang.org/doc/apps/mnesia/mnesia_chap4#atomicity>grouping multiple writers</a> with <a href=https://www.erlang.org/doc/man/mnesia#transaction-1>transactions</a> but ets does not. The atomicity contract only extends per single operation on a Table(s) read/write.</p><h2 id=isolation>Isolation</h2><p>Isolation is really about how we define the <em>logical concurrent access rules</em> of a <code>Table</code>. In ets we have different access modes for processes:</p><ul><li>public: all processes may read or write.</li><li>protected: all process may read but one exclusive writer.</li><li>private: single reader and writer.</li></ul><p>Why does this matter? Before it was hinted at why the MVCC paradigm <sup id=fnref:8><a href=#fn:8 class=footnote-ref role=doc-noteref>8</a></sup> exists &ndash; naive locking hurts all query performance, yet locks are desirable
because they ensure correct logical ordering &ndash; serializable/linearizability.</p><p>It&rsquo;s worth pausing to consider this for a moment.</p><p>Concurrency is a powerful concept, we can take three logically independent events A, B then C &ndash; potentially reorder them by alternating or <em>interleaving</em>
their execution&rsquo;s progress and reassemble them as A, B then C &ndash; sequential, nice & correct. Systems must be correct, but not necessarily sequential.</p><p>There&rsquo;s a hint of that infamous word here &ndash; a tradeoff, in a concurrent universe performance or correctness pick one? Sadly reality is more complex
and there are different shades on this spectrum that trade one thing by changing the definition of another <a href=https://en.wikipedia.org/wiki/Consistency_model>the devil is in the details</a>. You can tune consistency and change what isolation means &ndash; but that&rsquo;s yet further ahead, this problem is further compounded when you introduce a network call across tables but let&rsquo;s not try that optimisation tempting as it is.</p><p>What to do? Inline with the <em>more is better</em> philosophy of scaling an infamous default weakened guarantee of isolation is <em>snapshot insolation</em>, the <a href=https://en.wikipedia.org/wiki/Snapshot_isolation>cannonical isolation level</a>. The concurrency control works by keeping multiple versions on each write and matches read transactions to specific version of the database at a checkpoint matching both with a logical but not actual order. In a database like postgres you might be familiar with row or table level locks such as <code>FOR UPDATE</code> or <code>ACCESS EXCLUSIVE</code> which give stronger guarantees, in mnesia you have similar <a href=https://www.erlang.org/doc/man/mnesia#lock-2>locking semantics</a>.</p><p>What does this mean for ets? unlike Mnesia in :ets has no need for optimistic concurrency control mechanisms such as MVCC because it does not model the idea of a &ldquo;transaction&rdquo;, nor does it have <a href=https://www.erlang.org/doc/man/mnesia_registry>quorum</a> problems in a distributed/replicated setting which mask failures in a net-split mutiplying the difficulty and these are out of scope and are the key features mnesia provides.</p><p>Instead the time instantiation of a lock acquistion on a single node gives enough information to order reads or writes correctly relatively simpler between interleaving processes and enforcing the invariants <code>public</code>, <code>private</code> & <code>protected</code> leaving it up to the consumer to make informed choices on what concurrent data patterns make sense in the domain problem being solved.</p><h2 id=consistency>Consistency</h2><p>Consistency is a tricky topic. In a way we can think of <em>referential integrity</em> as a consistent property of a database but is it? You define a primary key and a foreign key and specify a logical relationship between entities based on this &ndash; but really you&rsquo;re defining an interface and specifying a contract with an invariant that must be implemented. ETS does not have referential integrity, check constraints or schema validation, it stores/retrieves data agnostic of the kind or shape and enforces a serializable/linearizable api for concurrent reads and writes to every function API.</p><p>ACID/BASE whatever are strange mental models for a few reasons:</p><ul><li>There&rsquo;s diverging understanding/interpretation of <a href=https://stackoverflow.com/questions/3736533/why-doesnt-mongodb-use-fsync/3737121#3737121>what this means</a></li><li>Although distinct are interwined concepts and are often garbled up in modern systems with distributed systems problems/concepts which further commingle the whole thing, it&rsquo;s a mess.</li><li>These models are supposed to <em>simplify</em> and <em>abstract</em> complex concurrency control but this is doubtful given that perhaps the non-trivial implementation complexity is removed but you still have to understand <em>how</em> databases (esp distributed ones) do this stuff which
<a href=https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/>feels terribly leaky</a>.</li></ul><h2 id=the-dumpster-fire-that-is-garbage-collection>The dumpster fire that is garbage collection</h2><p>So far we&rsquo;ve explored reading and writing data to the <code>Table</code> and <code>OrderedTable</code> but not deletion, what is deletion?</p><p>Deleting data can be thought about as <em>reclaiming</em> and <em>destroying</em>. What happens when a program needs memory? If it&rsquo;s <em>statically known</em> it&rsquo;s usually a well understood <a href=https://en.wikipedia.org/wiki/Stack-based_memory_allocation>let the compiler handle it problem</a>. Interfacing with a kernel or raw memory is complex and if a group of smart people can spend alot of time to get it right once and automagically solve it that would be nice indeed. This is the allure of automatic garbage collection. What happens when this model breaks down?</p><p>A brief mention of rust mentioned using atomic reference counts an implementation of <a href=https://doc.rust-lang.org/book/ch15-04-rc.html>automatic reference counting</a> and in go this operation is seemingly automatic and opaque. The resource allocation strategy is tightly coupled to the programming language and environment we intend our concrete key value implementation to eventually live, so at this point we bid farewall to go snippets and explore the problems of lifetimes, alignment & fragementation in rust.</p><p>⚠️⚠️ trigger warning <code>unsafe</code> rust ahead! ⚠️⚠️</p><h4 id=lifetimes-fragmentation--alignment>Lifetimes, Fragmentation & Alignment</h4><p>What really happens when you dynamically need memory? The compiler throws up its hand and decides it <a href=https://en.wikipedia.org/wiki/Undecidable_problem>can&rsquo;t figure it out</a>. You do it.</p><p>When the need arises&mldr; as it often does, you politely ask a kernel for some (and sometimes it says no!), and even when it does say yes, it typically lies to you about what you&rsquo;re getting &ndash; and once you get it, it&rsquo;s this weird stuff that doesn&rsquo;t make sense to your program and eventually&mldr; you have to give it back otherwise memory keeps growing forever (B)OOM.</p><p>Let&rsquo;s recap:</p><ul><li>You need to ask for memory</li><li>You need to keep <em>track of this memory</em> &ndash; it&rsquo;s <em>lifetime</em></li><li>You need to give it back</li></ul><p>As it turns out, the hard part is in the middle, keeping track of this forms a <a href=https://en.wikipedia.org/wiki/Graph_(abstract_data_type)>graph</a> and lots of hardwork has gone into figuring out algorithms to traverse this graph <em>especially in a concurrent setting</em> and packaging it into a nice abstraction &ndash; so nice, it&rsquo;s essentially automatic! Algorithms such as the tracing algorithm // mark and sweep serve this function and much more sophisticated systems exist in real languages like <a href=https://tip.golang.org/doc/gc-guide>go&rsquo;s awesome GC</a>, otherwise:</p><ol><li>In C everytime we malloc//free <strong>on demand</strong>. or <a href=https://github.com/jemalloc/jemalloc>Jemalloc.</a></li><li>RAII + reference counting + malloc/jemalloc</li><li><a href=https://zig.guide/standard-library/allocators/>DIY</a> &lt;&ndash; (we&rsquo;re here, oh no!)</li></ol><p>Although it&rsquo;s <em>possible</em> to do this in rust, it&rsquo;s <a href=https://matklad.github.io/2022/10/06/hard-mode-rust.html>atypical and has all sorts of nuances</a>. Why are we resorting to such a low, possibly error prone approach?</p><h4 id=being-a-good-neighbour>Being a good neighbour</h4><p>The current ETS exists tightly coupled to the internals of the erlang runtime system (erts) &ndash; ETS has its own private memory allocator <code>erts_db_alloc</code> and deallocator <code>erts_db_free</code> right on the BEAM virtual machine&rsquo;s heap in <code>erl_alloc.c</code> via <code>HAlloc</code>. There&rsquo;s far more going on than we&rsquo;re interested in knowing but the gist is these interfaces know how to allocate memory on a wide variety of architecture targets and environments and for the most part resemble C&rsquo;s malloc/free albeit with caveats &ndash; we need to play nice and share with our host runtime, this data-structure is a guest afterall and <a href=https://github.com/erlang/otp/blob/maint/erts/emulator/internal_doc/AutomaticYieldingOfCCode.md>must be submissive and yield</a> to the all powerful <a href=../../writing/a-peek-into-the-beam>scheduler</a> as we don&rsquo;t have <a href=http://erlang.org/pipermail/erlang-questions/2009-October/046899.html>BIF</a> <a href=https://www.erlang.org/doc/man/erlang#description>status</a>.</p><h4 id=a-detour-for-just-enough-web-assembly>A detour for just enough web assembly</h4><p><a href=https://webassembly.org/>Webassembly</a> is a pretty cool project. The web has four official langauges: html, css, javascript and webassembly. It&rsquo;d be nice
if you could write rust for your browser no? perhaps you&rsquo;d like to ship a runnable binary? Games, figma and containers &ndash; without docker. If this key-value store is going to exists agnostic of wheter it happens to run inside webassembly or <code>x86-64 linux</code> wouldn&rsquo;t it be nice to virtualize all the things?</p><h4 id=making-a-bad-contrived-allocator>Making a bad contrived allocator</h4><p>Other than supporting a target like webassembly, specifying a case-by-case allocation strategy per domain problem can in theory be always more performant<sup id=fnref:9><a href=#fn:9 class=footnote-ref role=doc-noteref>9</a></sup> than relying on an automatic garbage collector and in <em>hard real-time systems</em> this is a
table stakes requirement. In rust there are several common <em>implicit</em> <a href=https://en.cppreference.com/w/cpp/language/raii>RAII inspired</a> strategies to manage heap memory allocation all within the ownership/borrowing model and dellocation with the <a href=https://doc.rust-lang.org/std/ops/trait.Drop.html><code>Drop</code></a> trait.</p><p>Here we have well known reference counted smart pointers - <code>Rc</code>, <code>Arc</code> or perhaps directly pushing onto the heap using <code>Box</code> and somewhat more esoteric clone on write <a href=https://doc.rust-lang.org/std/borrow/enum.Cow.html><code>Cow</code></a> semantics. How does one DIY an allocator?</p><p>What do you need? &ndash; it&rsquo;s entirely dependent on the nature of the program!</p><p>Here we can model the space required to fit each key-value as a node on a linkedlist. An illustrative example is a <a href=https://en.wikipedia.org/wiki/Slab_allocation>slab allocator</a> using a <a href=https://en.wikipedia.org/wiki/Free_list><em>free list</em></a>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=c1>// statically start with 10 slots of 4096 bytes
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span><span class=w> </span><span class=no>INITIAL_BLOCKS</span>: <span class=kt>usize</span> <span class=o>=</span><span class=w> </span><span class=mi>10</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=c1>// typical page size in bytes on linux x86-64
</span></span></span><span class=line><span class=cl><span class=c1></span><span class=k>const</span><span class=w> </span><span class=no>DEFAULT_BLOCK_SIZE</span>: <span class=kt>usize</span> <span class=o>=</span><span class=w> </span><span class=mi>4096</span><span class=p>;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>struct</span> <span class=nc>ListNode</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>size</span>: <span class=kt>usize</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>next</span>: <span class=nb>Option</span><span class=o>&lt;</span><span class=nb>Box</span><span class=o>&lt;</span><span class=n>ListNode</span><span class=o>&gt;&gt;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=k>pub</span><span class=w> </span><span class=k>struct</span> <span class=nc>FreeList</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=n>head</span>: <span class=nb>Option</span><span class=o>&lt;</span><span class=nb>Box</span><span class=o>&lt;</span><span class=n>ListNode</span><span class=o>&gt;&gt;</span><span class=p>,</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>A free list is a linked list where each node is a reference to a contigous block of homogeneous memory unallocated <em>somewhere</em> on the heap. To allocate we specify the underlying initial block size of virtual memory we need, how many blocks and how to align said raw memory:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>impl</span><span class=w> </span><span class=n>FreeList</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=k>fn</span> <span class=nf>allocate</span><span class=p>(</span><span class=o>&amp;</span><span class=k>mut</span><span class=w> </span><span class=bp>self</span><span class=p>,</span><span class=w> </span><span class=n>size</span>: <span class=kt>usize</span><span class=p>,</span><span class=w> </span><span class=n>align</span>: <span class=kt>usize</span><span class=p>)</span><span class=w> </span>-&gt; <span class=o>*</span><span class=k>mut</span><span class=w> </span><span class=kt>u8</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span><span class=n>todo</span><span class=p>()</span><span class=o>!</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>Deallocation is as simple as dereferencing the raw pointer and marking that block as safe for reuse back to the kernel:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-rust data-lang=rust><span class=line><span class=cl><span class=k>impl</span><span class=w> </span><span class=n>FreeList</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=k>pub</span><span class=w> </span><span class=k>fn</span> <span class=nf>deallocate</span><span class=p>(</span><span class=o>&amp;</span><span class=k>mut</span><span class=w> </span><span class=bp>self</span><span class=p>,</span><span class=w> </span><span class=n>ptr</span>: <span class=o>*</span><span class=k>mut</span><span class=w> </span><span class=kt>u8</span><span class=p>,</span><span class=w> </span><span class=n>size</span>: <span class=kt>usize</span><span class=p>,</span><span class=w> </span><span class=n>align</span>: <span class=kt>usize</span><span class=p>)</span><span class=w> </span><span class=p>{</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>        </span><span class=n>todo</span><span class=p>()</span><span class=o>!</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=p>}</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w></span><span class=p>}</span><span class=w>
</span></span></span></code></pre></div><p>Typically an implementation of the <code>GlobalAlloc</code> trait is where all heap memory comes from this is called the <a href=https://doc.rust-lang.org/std/alloc/struct.System.html>System allocator</a> in rust which make syscalls like <code>mmap</code>, <code>sbrk</code> and <code>brk</code> and but we don&rsquo;t want to simply throw away the global allocator and talk to the operating system ourselves &ndash; oh goodness no, we&rsquo;d want to treat it just like <code>HAlloc</code> and carve out a region of memory just for this rather than pairing allocations and deallocations everytime we can amortize memory per value stored and simplify some lifetimes. When this is not possible we default to reference counting over a pre-allocated smaller region like <code>Box</code>.</p><p>We must now consider the <code>types</code> of the key and value. In erlang every value is a <code>Term</code><sup id=fnref:10><a href=#fn:10 class=footnote-ref role=doc-noteref>10</a></sup> and serializing and deserializing to a specific Term&rsquo;s size and type will also be the responsibility of our Allocator, here we need to be careful as we traverse the cache line that we aren&rsquo;t unnecessarily thrashing the CPU and minimizing context switches and leveraging if any vectorized instruction sets. Luckily there&rsquo;s an awesome
in-memory format lots of smart folks spent time working on and open sourced called <a href=https://arrow.apache.org/>Arrow</a> which does just that!</p><h1 id=gotta-go-fast>Gotta Go Fast</h1><p><img src=/Speed_Racer_behind_the_wheel.webp alt="Speed racer 1967"></p><p>It might not seem like it, but we&rsquo;ve covered a lot of ground, our key value store&rsquo;s <a href=https://en.wikipedia.org/wiki/Database_engine>storage engine</a> is almost ready. We have a basis to discuss algorithmic complexity and data structure design, concurrency control with ACID, and a vocabulary to express its bit for bit layout in-memory and access path, however can we do better than lock groups? &ndash; the answer is maybe!</p><p>There are two optimisation architectures we haven&rsquo;t discussed yet:</p><ul><li>no shared state, message passing and thread per core pinning<sup id=fnref:11><a href=#fn:11 class=footnote-ref role=doc-noteref>11</a></sup></li><li>lock free/wait free techniques<sup id=fnref:12><a href=#fn:12 class=footnote-ref role=doc-noteref>12</a></sup></li></ul><p>Hold on?! Message passing concurrency? Isn&rsquo;t this what elixir/erlang has native support for?</p><ul><li>use of lock free data structures/behaviour across reads - concurrent skip list crash course, why?</li></ul><h2 id=persistence-and-durability>Persistence and Durability</h2><p>ETS has an alternative implementation call Disk-Based Term Storage &ndash; I have no interest in <a href="https://www.youtube.com/watch?v=4HC5GDoixiA">wrastling</a> with the complexities of <code>fsync</code> but for completeness, in theory however would one implement it? To do that we have to re-examine the assumption of durability. What happens when you write some data to disk?</p><p>There are roughly three odd roads/paths on a single node db:</p><ul><li>you write to a buffered read/write stream (you&rsquo;ve probably done this, but your writes aren&rsquo;t actually written - only scheduled.)</li><li>you write to virtual memory and negotiate magic with the kernel.</li><li>you ACTUALLY write directly to memory.</li></ul><p>Why does the Kernel/OS want you to buffer or write to &ldquo;fake&rdquo; memory in the first place? &ndash; it&rsquo;s half performance and half security concerns.</p><blockquote><p>disks have relatively long seek times, reflecting how long it takes the desired part of the disk to rotate under the read/write head. Once the head is in the right place, the data moves relatively quickly, and it costs about the same to read a large data block as it does to read a single byte</p></blockquote><p>There&rsquo;s some nuance wheter this is an SSD or HDD, but the gist is it&rsquo;s lipstick on a pig. The data has to travel up, traverse the dragons and castles of memory heirarchy and the weird and wonderful complexity an OS hides &ndash; <a href=https://pages.cs.wisc.edu/~remzi/OSFEP/intro-syscall.pdf>syscalls are an abstraction remember?</a> Most of the time Buffered IO works and when that&rsquo;s unacceptable, wrangling with mmap is an option &ndash; but <a href=https://www.cidrdb.org/cidr2022/papers/p13-crotty.pdf>there are caveats</a>, so perhaps you definitely want to directly write to memory. It&rsquo;s obviously the &ldquo;right&rdquo; choice no? &ndash; but now you start talking about pages, caches, pools, dirty things? and all <a href=https://15445.courses.cs.cmu.edu/fall2020/notes/05-bufferpool.pdf>sorts of hidden fun goodies</a> that shave off years from your limited life &ndash; <a href=https://www.postgresql.org/docs/current/wal-reliability.html>WAL me daddy</a>. No wonder <a href=https://wiki.postgresql.org/wiki/Fsync_Errors>getting this right is hard</a> and <a href=https://danluu.com/fsyncgate/>riddled with ugly bugs</a>. However there&rsquo;s <a href=https://github.com/axboe/liburing/wiki/io_uring-and-networking-in-2023>renewed hope</a> in a <a href=https://github.com/axboe/liburing>shiny new api</a> that&rsquo;s perhaps the future once the <a href=https://lwn.net/Articles/902466/>bugs gets ironed out</a>.</p><p>Instead we can ensure that our limited focus is on queries to disk/ram are READ ONLY - so we can freely do mmap magic. Produce nice <code>Future</code> streaming access methods with the query engine &ndash; more on that later and <em>purposefully discourage</em> use of the write api to disk: durable, correct, blocking and slow if you try to &ndash; PRs welcome :)</p><h2 id=querying>Querying</h2><p>Every good database needs good ergonomics for querying! SQL is popular but is a complex and large standard to implement. Luckily &ndash; <a href=https://arrow.apache.org/datafusion/><em>I don&rsquo;t really have to</em></a>. Theres lots of syntax for querying key-value stores, redis has one, mongodb has one and even postgres patched in one! There are probably thousands of these kinds of languages &ndash; and
of course ets has one called a <code>match_spec</code> &ndash; If you&rsquo;d like to see this <a href=https://github.com/hailelagi/tsunami/issues/4>ask!</a> and if you want to learn about the match spec <a href=https://github.com/hailelagi/hailelagi.com/issues/1>leave a thumbs up!</a> this version <strong>does not</strong> ship with the match_spec api.</p><p>Here&rsquo;s a thought - what if you could query runtime data transaparently across all your erlang nodes :) wouldn&rsquo;t that be something?</p><p>This doesn&rsquo;t work &ndash; but it <em>could</em>.</p><h2 id=testing-methodology>Testing Methodology</h2><ul><li>unit testing challenges, tight coupling etc</li><li>conformance with the upstream erts(erlang runtime system) ETS public api and behaviour</li><li>100% erts TEST SUITE coverage</li></ul><p>methodology, coverage, tools, loom, address sanitizer etc insert graphs of benchmark results</p><h2 id=notes--references>Notes & References</h2><div class=footnotes role=doc-endnotes><hr><ol><li id=fn:1><p>[†1] Immutability is not necessarily a performance bottleneck. This is a common misconception about functional languages/semantics and more broadly a misunderstanding of the nuances of immutability and its advantages especially with respect to cache coherency and concurrency. Flavors of LSM-Tree based persistent key-value stores or append-only Log-Structured Hash Tables can and have been modelled in erlang. It just so happens <em>this</em> key value store&rsquo;s properties are hard to model entirely with functional semantics.&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:2><p><a href=http://doi.acm.org/10.1145/2505305.2505308>On the scalability of the Erlang term storage</a>&#160;<a href=#fnref:2 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:3><p><a href=https://www.postgresql.org/docs/16/hash-intro.html>Hash Indexes in postgres</a>&#160;<a href=#fnref:3 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:4><p><a href=https://dev.mysql.com/doc/refman/8.3/en/innodb-adaptive-hash.html>Adaptive Hash Index in mysql</a>&#160;<a href=#fnref:4 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:5><p><a href=https://www.postgresql.org/docs/current/hstore.html>Hstore - key/value datatype in postgres</a>&#160;<a href=#fnref:5 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:6><p><a href=https://doi.org/10.1145/2633448.2633455>More Scalable Ordered Set for ETS Using Adaptation</a>&#160;<a href=#fnref:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a>&#160;<a href=#fnref1:6 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:7><p><a href=https://www.erlang.org/doc/man/ets#concurrency>Concurreny in ETS</a>&#160;<a href=#fnref:7 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:8><p><a href=https://www.postgresql.org/docs/current/mvcc.html>MVCC introduction</a>&#160;<a href=#fnref:8 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:9><p><a href=https://www.kernel.org/doc/html/next/core-api/memory-allocation.html#selecting-memory-allocator>Memory Allocation - Linux</a>&#160;<a href=#fnref:9 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:10><p><a href=https://www.erlang.org/doc/reference_manual/data_types>Erlang data types</a>&#160;<a href=#fnref:10 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:11><p><a href=https://github.com/DataDog/glommio>Glommio - thread per core</a>&#160;<a href=#fnref:11 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li><li id=fn:12><p><a href="https://learn.microsoft.com/en-gb/windows/win32/dxtecharts/lockless-programming?redirectedfrom=MSDN">Lockless Programming Considerations for Xbox 360 and Windows</a>&#160;<a href=#fnref:12 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></div></article></main><footer id=footer><a href=https://github.com/hailelagi/blog>source</a>
Copyright © 2024 Haile Lagi<div id=sign-key><span>GPG key ID: 0298F4203ADC85E8</span></div></footer></body></html>